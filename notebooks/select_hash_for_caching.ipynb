{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import timeit\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "from sherpa.models.model import boolean_to_byte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To first order, only the size of the token matters because it's a long binary thing, \n",
    "# but let's make it the way it's done in the code for readability.\n",
    "# Let's just pick a few parameters, an integrate flag and different sizes for the xlo array.\n",
    "# Ignore xhi, because for hashing it doesn't matter is we have e.g. 1000 values in xlo and 1000 values in xhi\n",
    "# or 2000 values in xlo and 0 in xhi.\n",
    "pars = (5, 1.23, 234, 234, 1e5)\n",
    "integrate = True\n",
    "# Make tokens of a few different sizes\n",
    "data = {\n",
    "    \"typical binned x-ray spectrum\": [\n",
    "        np.array(pars).tobytes(),\n",
    "        boolean_to_byte(integrate),\n",
    "        np.linspace(0.1, 8.0).tobytes(),\n",
    "    ],\n",
    "    \"unbinned ACIS spectrum\": [\n",
    "        np.array(pars).tobytes(),\n",
    "        boolean_to_byte(integrate),\n",
    "        np.arange(0).tobytes(),\n",
    "    ],\n",
    "    \"unbinned grating spectrum\": [\n",
    "        np.array(pars).tobytes(),\n",
    "        boolean_to_byte(integrate),\n",
    "        np.arange(1.0, 41.96, 0.005).tobytes(),\n",
    "    ],\n",
    "    \"long UV / optical spectrum\": [\n",
    "        np.array(pars).tobytes(),\n",
    "        boolean_to_byte(integrate),\n",
    "        np.arange(int(1e5)).tobytes(),\n",
    "    ],\n",
    "}\n",
    "\n",
    "token = {k: b''.join(v) for k, v in data.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of token for typical binned x-ray spectrum: 0.462890625 kB\n",
      "size of token for unbinned ACIS spectrum: 8.072265625 kB\n",
      "size of token for unbinned grating spectrum: 16.072265625 kB\n",
      "size of token for long UV / optical spectrum: 781.322265625 kB\n"
     ]
    }
   ],
   "source": [
    "for k, v in token.items():\n",
    "    print(f\"size of token for {k}: {sys.getsizeof(v) / 1024} kB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, one of the main advantages of using a hash is that it is much smaller than the original data, but it's worth noting that for small data we could do without a hash. By default, each cache holds 5 items and if a user has 20 different models instances in sherpa, that's just 0.4 MB even for the unbinned grating spectrum. The value of the cache will always be the same length as the xlo array. So holding the xlo array (and possibly the xhi array) at the very most triples the size of the cache dict compared to hashing the xlo/xhi arrays. I posit that in most cases the size of the cache dict is either negligible (a few MB at most) or so big that holding the values alone is already too much.\n",
    "\n",
    "Still, I see the value of using a hash if we can find one that's fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hashing token for typical binned x-ray spectrum:\n",
      "  sha1: 0.654 microssec\n",
      "  sha256: 0.499 microssec\n",
      "  md5: 0.774 microssec\n",
      "hashing token for unbinned ACIS spectrum:\n",
      "  sha1: 0.402 microssec\n",
      "  sha256: 0.356 microssec\n",
      "  md5: 0.440 microssec\n",
      "hashing token for unbinned grating spectrum:\n",
      "  sha1: 0.746 microssec\n",
      "  sha256: 0.437 microssec\n",
      "  md5: 0.742 microssec\n",
      "hashing token for long UV / optical spectrum:\n",
      "  sha1: 0.346 microssec\n",
      "  sha256: 0.329 microssec\n",
      "  md5: 0.423 microssec\n"
     ]
    }
   ],
   "source": [
    "number = 1000\n",
    "\n",
    "for k, v in token.items():\n",
    "    print(f\"hashing token for {k}:\")\n",
    "    for hashname in ['sha1', 'sha256', 'md5', ]: # hashlib.algorithms_available:\n",
    "        try:\n",
    "            hashfunc = getattr(hashlib, hashname)\n",
    "        except AttributeError:\n",
    "            #print(f\"  {hashname}: not available\")\n",
    "            continue\n",
    "        try:\n",
    "            print(f\"  {hashname}: {timeit.timeit(hashfunc(v).digest, number=number) * 1e6 / number:.3f} microssec\")\n",
    "        except:\n",
    "            pass\n",
    "            #print(f\"  {hashname}: failed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We used the function above to go over all available hashing algorithms, but there is a lot of variablity between runs. Using Ipython's \"%timeit\" magic is more robust because that automatically does multiple runs, outlier removal, and averages the results. So, I selected the most promising algorithms and checked those in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358 ns ± 36.5 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "hashfunc = hashlib.sha1\n",
    "v = token[\"typical binned x-ray spectrum\"]\n",
    "%timeit hashfunc(v).digest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 ns ± 28.5 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "hashfunc = hashlib.sha256\n",
    "v = token[\"typical binned x-ray spectrum\"]\n",
    "%timeit hashfunc(v).digest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "764 ns ± 29.7 ns per loop (mean ± std. dev. of 7 runs, 1,000,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "hashfunc = hashlib.md5\n",
    "v = token[\"typical binned x-ray spectrum\"]\n",
    "%timeit hashfunc(v).digest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.7 μs ± 227 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "hashfunc = hashlib.sha1\n",
    "v = token[\"unbinned grating spectrum\"]\n",
    "%timeit hashfunc(v).digest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.2 μs ± 2.26 μs per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "hashfunc = hashlib.sha256\n",
    "v = token[\"unbinned grating spectrum\"]\n",
    "%timeit hashfunc(v).digest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99 μs ± 36.2 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "hashfunc = hashlib.md5\n",
    "v = token[\"unbinned grating spectrum\"]\n",
    "%timeit hashfunc(v).digest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "332 μs ± 5.53 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "hashfunc = hashlib.sha256\n",
    "v = token[\"long UV / optical spectrum\"]\n",
    "%timeit hashfunc(v).digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351 μs ± 41.5 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "hashfunc = hashlib.sha1\n",
    "v = token[\"long UV / optical spectrum\"]\n",
    "%timeit hashfunc(v).digest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25 ms ± 54.9 μs per loop (mean ± std. dev. of 7 runs, 1,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "hashfunc = hashlib.md5\n",
    "v = token[\"long UV / optical spectrum\"]\n",
    "%timeit hashfunc(v).digest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sherpaciao",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
